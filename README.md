# Documentation


<h3>Project Objective</h3>
The objective of this project is to design, implement and execute an ETL pipeline using PySpark to migrate data from a PostgreSQL database to a SQL Server database.
The pipeline should be designed to handle large amounts of data and ensure data integrity during the migration process. 
The ETL pipeline should include steps for extracting data from the PostgreSQL database, transforming the data to match the schema of the SQL Server database, 
and loading the data into the SQL Server database. The ultimate goal is to have the data in the SQL Server database accurately reflect the data in the PostgreSQL database
with minimal data loss and minimal disruption to ongoing operations.
<br />
<h3>Project Instruction</h3>
<p>1. Install the PySpark library<p/>
<p>2. Download the JDBC driver for PostgreSQL and Microsoft SQL Server<p/>
<p>3. Clone this repository<p/>
<p>4. Set up spark driver to the JDBC driver<p/>
<p>5. Set up the PosgreSQL and SQL Server credentials (username, password, and database name)<p/>
<p>6. Run the program<p/>
